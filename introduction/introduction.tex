\chapter{Introduction}\label{chapter:Introduction}
This project started as an attempt to bring computer aided verification to bear on a classic text of modern mathematics: David Hilbert's \emph{Grundlagen der Geometrie}. When we began, the idea had already gathered some interest in the formal verification community. Dehlinger et al~\cite{DehlingerFOG} had tried to reformulate Hilbert's axiomatics along constructivist lines, and we were initially building on work by Meikle and Fleuriot~\cite{MeikleFleuriotFormalizingHilbert}, who tried to address questions concerning the logical rigour of Hilbert's deductions. 

During the research, we withdrew from our broader aims to pursue deeper ones. We unearthed unexpected subtleties and made fine-grained observations in just the first two of Hilbert's five groups of axioms, groups which Hilbert spent little time investigating. These axioms characterise, not the full Euclidean geometry which Hilbert developed, but a much weaker, non-metrical \emph{ordered geometry}.

In the next section, we give a brief introduction to the various historical strands that can be tied to the verification of Hilbert's axiomatics, and thus try to explain why it has had interest to the theorem proving community. The details discussed are elaborated by Kleiner~\cite{RigourProof} and Nagel~\cite{NagelModernGeometry}.

\section{The Early Axiomatic Method in Geometry}
We motivated our earlier work~\cite{ScottMScThesis} verifying Hilbert's \emph{Grundlagen der Geometrie} as concluding a story that began with what is probably the most influential~\cite{BoyerEuclidInfluence} mathematical text ever written: Euclid's \emph{Elements}~\cite{HeathElements}. 

The \emph{Elements} was probably an introductory textbook to Greek geometry. It described in meticulous detail how one can construct and reason about simple geometrical diagrams using a ruler and compass, how one can do algebra where numbers are understood to refer to line segments, how one can develop a theory of proportions or ratios in geometrical terms, and how one can solve problems in what we would nowadays regard as number theory. 

The results contained in Euclid's text were probably already well-known at the time, and the book was not even the first of its kind. Its legacy is presumably due to the extent to which Euclid was able to systematise so much of his contemporary knowledge and place it on an extremely secure footing, safe from the foundational crisis in the discovery of incommensurable magnitudes. Euclid was able to recover, from readily accepted axioms, a wealth of interesting geometrical results by systematically deriving them from just ten postulates or axioms\footnote{We have grouped Euclid's ``postulates'' and ``common notions'' together here.}. This feat has inspired generations since. Aubrey gives a delightful account of Thomas Hobbes expressing scepticism at a mathematical proposition in Euclid's \emph{Elements}, and only becoming convinced of its truth as he traced the cross-referenced hypotheses through logical derivations all the way back to Euclid's original axioms~\cite{ElementaryGeometryRoe}. Now, over two millenia later, the structure of Euclid's text, broken down as it is into axioms, definitions, theorems and proofs, still characterises the structure of contemporary pure mathematics.

The simplicity of Euclid's axioms is still remarkable. Euclid permits himself only the simplest geometrical toolkit, given by five axioms, with which he must then obtain and reason about all other constructions and geometrical theory. He effectively imposes a severe handicap on himself, not even permitting himself the means to draw a line segment of given length emanating from a given point. The permissibility of even this simple technique must be carefully demonstrated using the much more primitive toolkit.

The presence of such a handicap will be a theme running through the current thesis. Hilbert himself imposes an even stricter handicap and an even more primitive toolkit, but, as we shall see in later chapters, it is not clear how far Hilbert respects it. Sometimes, he will expend great effort deriving fairly obvious results, while glossing over results that turn out to be fiendishly complicated. One of these results in particular will be detailed from Chapters~\ref{chapter:JordanInformal} to~\ref{chapter:JordanVerification2} of the present thesis.

\subsection{Rigorisation}
Modern pure mathematics is partly characterised by a commitment to logical correctness and Euclid's \emph{Elements} went largely uncontested in this respect until the 19th century. Here, the tide was generally turning against the sloppy approaches in mathematics, such as those which seemed to plague the calculus, the foundations of which, as Berkeley had argued~\cite{BerkeleyNewton}, were hardly clear. In the 19th century, Cauchy settled the matter. His ideas, partly refined by Weierstrass, introduced the modern epsilon-delta definitions~\cite{RigorousCalculus}, while Dedekind closed the final gaps by giving a model for the elusive \emph{continuum}~\cite{DedekindsCuts}. 

At the same time, the priority of geometry was being contested by the successes of algebraic approaches based on Cartesian coordinates, and mathematics as a whole was taking an abstract turn in both synthetic geometry, with the introduction of ideal points in projective geometry, and the growing acceptance of imaginary and negative numbers in algebra. Here, the axiomatic method was able to serve a new purpose in capturing the emerging abstractions, which would eventually be refined in the form of axiomatisations for abstract algebra, topology and measure theory to name a few.

Synthetic geometry was revitalised along rigorous lines by Pasch, who has been called the ``father of rigour in geometry''~\cite{PaschToPeano}. He developed his own axiomatic system for geometry, and in so doing, closed a major logical gap in Euclid's \emph{Elements} by introducing axioms for a \emph{betweenness} relation. He then secured the logical correctness by insisting that all logical deductions must take place without reference to the intuitive meaning of terms such as ``point'', ``line'' and ``between.'' 

Partly embracing the abstract turn in the 19th century, Pasch initially justified his axioms as idealisations of empirical hypotheses, but as his treatise progresses, he embraces a more abstract view by allowing the meaning of his primitive notions to be generalised. This is needed, in part, to explain the theory of duality, wherein the terms ``point'' and ``line'' can be swapped in theorems without changing their validity.

Finally, we mention Peano, who recast Pasch's axiomatisation along modern symbolic lines and further embraced the abstract turn by regarding his postulates as merely characterising equivalent classes of possible structures. The importance of Peano for this story is that he was not only part of the strand following the rigorisation of geometry, but was an important inspiration to Russell~\cite{PrinciplesOfMathematics}, who would complete the first major formal verification effort in his monumental \emph{Principia Mathematica}. 

\section{The \emph{Grundlagen der Geometrie}}
Hilbert published his text following a lecture series in the foundations of geometry. The book was so successful that it had ten editions in both German and English, and was hailed as the most influential book in a hundred years~\cite{BirkhoffHilbertInfluence}. 

The Grundlagen is particularly notable for its endorsement of logical rigour. In a famous remark, Hibert demanded that all references to ``point'', ``line'' and ``plane'' in his text should be replacable with ``mug'', ``table'' and ``chair''. In this, he was reinforcing Pasch's idea that all deductions must proceed without reference to the intuitive meaning of the terms involved. 

However, the most notable achievement of Hilbert is probably not in his axiomatics, but in his \emph{metamathematics}. He made axiom systems an object of mathematical scrutiny in their own right, and carefully analysed which axioms were independent of others. To do this, he took abstraction a stage further, by assigning interpretations to his axioms where points were now identified with non-geometrical entities such as real algebraic functions. He also carefully analysed the minimal sets of axioms that could be used to define a geometrically grounded arithmetic, and made some effort to establish the categoricity of his full set of axioms.

\subsection{Verification}
The computer assisted verification of the axiomatics and elementary consequences of Hilbert's \emph{Grundlagen der Geometrie} is anticipated in two reviews of the text by Veblen~\cite{VeblenHilbertReview} and Poincar\'{e}~\cite{PoincareReview}, both of whom mention logic computers that had been developed in the 19th century~\cite{LogicMachines}, and the latter of whom mentions Peano's investigation of a symbolism for modern formal logic. This verification is the subject of the present thesis.

The possibility of a formal verification of mathematical theories such as geometry was made possible by the highly expressive formal systems developed by Frege, Russell and Whitehead. Frege abandoned his work here when Russell pointed out the famous paradox of his name, one which contributed to the growing sense of crisis in the foundations of logic itself. Russell and Whitehead perservered by revising Frege's system, but the heavy labour and seeming endlessness involved in verifying even the simple theory given in the \emph{Principia Mathematica} nearly drove an already melancholy Russell to suicide~\cite{RussellSuicide}. Its completion left him completely exhausted.

Poincar\'{e} was punishingly dismissive of the project, regarding the programme as offering mathematicians nothing but ``shackles''~\cite{PoincareShackles}, and even going so far as to call Peano's projects and the aims of verification ``peurile''~\cite{PoincareReview}. This criticism seems short-sighted with the crises that have appeared in 20th century mathematics. Proofs have become so long and convoluted that they can not always be verified by individual human readers~\cite{WhitherMathematics}. Besides which, all the shackles in Russell and Whitehead's research programme can be illeviated with the help of machines.

\subsubsection{Computer Assistance}
By the mid-1950s, as programmable computers were coming to prominence, Herbert Simon built a logic machine which could automatically prove all the theorems in Russell's \emph{Principia}, thereby paving the way for computer assisted verification which could relieve the poor human of the Herculean task of manually deriving the theorems. It is somewhat sad that, with the advent of such machines, Russell reflected on his manual verification as ``wasted'' effort~\cite{SimonObituary}.

A decade after Simon's logic machine came DeBruijn's AUTOMATH project and the first computer \emph{assistant} for formally verifying mathematical theories, which was successfully used to verify Landau's classic text on real analysis~\cite{LandauGrundlagen,LandauAUTOMATH}. An observation was made in this project which has largely stood up: even with computer assistance, there is a wide gulf between mathematical proofs as they appear in the literature and the formal proof steps used in computer aided verification. A single logical inference might be multiplied to many logical steps in the verification, and the term ``DeBruijn'' factor was coined for the multiplier. Besides the DeBruijn factor, there is also the time factor involved. Hales estimates that a single page of mathematics requires a week for an expert to formally verify~\cite{HalesFormalisingCost}. Finally, there is the disparity in the representation between informal and formalised mathematics. For a perspicious example of such disparities, consider Lamport's recent example concerning the proof that the sum of the first $n$ triangle numbers is $\tfrac{1}{2}n(n+1)$~\cite{ProofMessageCertificate}.

Difficulties aside, computer assisted verification has had some astounding successes. Take the Four Colour Theorem. This is a century old outstanding problem. Its first 1976 proof was assisted by inscrutable algorithms and was rightly viewed with suspicion, but the whole theorem has now been meticulously verified by Gonthier in an extremely robust verifier~\cite{GonthierFCT}. According to Hales, the verification makes the theorem one of the most well-established results in all of mathematics, and Gonthier has gone on to lead the project to verify the Feit-Thompson Theorem, a milestone in verifying the troublesome classification of all finite simple groups. Finally, as of writing, the verification of the outstanding four century old Kepler Conjecture is approaching completion~\cite{flyspeck}.

\subsubsection{Reducing the DeBruijn Factor}
The gulf between formal verifications and practised mathematics concerns us. Like Meikle and Fleuriot, we wanted our verification of Hilbert's axiomatics to allow us to explore potential redundancies, logical gaps, and unbalanced presentation in Hilbert's prose. Verification was to be our analytical tool, as it had been conceived of by Frege~\cite{ProofsAboutProofs}. 

However, we initially felt there was little hope of analysing Hilbert's prose with verifications so long as there was such a gulf between the prose and the formalisation. We needed to close that gap, to bring our verification as close as possible to Hilbert's intentions. Only then could we hope to validate his approach or identify possible cracks in his presentation.

To that end, we have emphasised a particular style of verification which aims to be close to the ``mathematical vernacular''~\cite{MizarMathematicalVernacular}, and a style which respects the logical progressions typical of synthetic geometry. Just as in synthetic geometry, we reason to our theorems by building \emph{diagrams}, obtaining configurations of points, lines and planes. Our axioms are then intended to allow us to derive interesting properties of these configurations.

\section{Aims and Contributions}
As we stated at the beginning of this introduction, our initial aims for the project evolved over time. We had initially hoped to verify all five groups of Hilbert's axioms and their elementary consequences. Instead, we found there were many interesting sights to be found in just the first two groups. 

In focusing on these two groups, we have produced a verification of \emph{ordered geometry}. This geometry, which lacks any notion of angle, parallels or distance, is a good deal more general than full Euclidean geometry, and to some extent, it has been investigated independently of other geometries~\cite{AxiomaticsOrderedGeometry}.

It turns out that the two groups contain most of Hilbert's axioms, which is interesting because they mostly go unmentioned by Hilbert. It is perhaps no surprise then that our efforts to bring the DeBruijn factor of our verifications as close to 1 as possible has us investigating these axioms in some detail. The investigation culminates in a verification of the polygonal Jordan Curve Theorem whose complexity dwarves all our other verifications put together.

We now give the contributions of the thesis. We have produced:
\begin{enumerate}
\item a formalisation of the axioms for ordered geometry in Hilbert's \emph{Grundlagen der Geometrie};
\item a fully verified synthetic proof of the Polygonal Jordan Curve Theorem using only axioms for incidence and order;
\item a combinator language allowing users to define complex search strategies to assist declarative proof, and an application of this language to incidence reasoning;
\item an informal existence proof that the ``toy'' declarative language Mizar~Light~\cite{MizarLight} can cope with non-trivial verifications of synthetic geometry;
\item a case-study in developing readable verifications with a low DeBruijn factor;
\item a detailed investigation of the logical character of Hilbert's text.
\end{enumerate}

We have ordered these from ``hard'' contributions to ``soft'' ones. The formalisation and verification are virtually beyond reproach, and can be machine-checked by downloading the code at \url{https://github.com/Chattered/hilbert} and running it in the HOL~Light theorem prover~\cite{HOLLight}. Note that since we have preferred proofs optimised for human readability over proofs optimised for the computer, the full verification takes some time to run (roughly 30 minutes on an Intel Core 2 2.53GHz machine.)

Our latter contributions can be tempered somewhat. We are officially outside the scholarly community which investigates the history of mathematics, and thus cannot claim authority on their turf. However, in formally verifying Hilbert's proofs in a \emph{faithful} way, we have had to investigate every line in pedantic detail, and we believe that our insights and observations can be useful to those in the scholarly community.

\section{Organisation}
The thesis is organised as follows. In Chapter~\ref{chapter:Background} we deal with some necessary preliminaries concerning our theorem prover, its associated proof tools and its logical foundations. In Chapter~\ref{chapter:Axiomatics}, we introduce Hilbert's first two groups of axioms and discuss the various problems they introduce in terms of staying faithful to Hilbert in verification. In the next chapter, we discuss how to deal with these problems by introducing new automation in the form of a combinator language for theorem discovery. We then look in Chapter~\ref{chapter:Group2Eval} at Hilbert's first three prose proofs, using each as a case-study for our automated tool, and drawing out numerous observations about the proofs themselves. 

In Chapters~\ref{chapter:LinearOrder} and \ref{chapter:HalfPlanes}, we get into the meat of ordered geometry, dealing with the matter of linear and two-dimensional ordering in the plane, and finalising the concepts and additional automation that sees us through our final verification effort. This last effort is dealt with across four chapters. In Chapter~\ref{chapter:JordanInformal}, we lay out the problem and describe some high-level proofs and their weaknesses. In Chapter~\ref{chapter:JordanFormalisation}, we give the full formalisation of the theorem in a self-contained form which explains exactly what is to be verified. The full verification itself is divided into two parts across Chapters~\ref{chapter:JordanVerification1} and~\ref{chapter:JordanVerification2}.

We conclude in Chapter~\ref{chapter:Conclusion}. 

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
